{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Visualization of PyTorch JIT Modules\n",
    "\n",
    "Copyright 2022 by Thomas Viehmann\n",
    "\n",
    "Recently, PyTorch turned 5 years old Today is the 5th anniversary of my first post to the PyTorch forums.\n",
    "I have had the honor of contriuting to PyTorch quite a while and have met many great people from the community.\n",
    "\n",
    "To celebrate, I'm dusting off a two-year old visualization notebook and make the visualizations clickable to expand modules.\n",
    "\n",
    "One caveat: Aside from being very hacky, I would expect names to not necessarily be completely stable across PyTorch releases, so you might not get the same pre-expanded diagrams.\n",
    "\n",
    "So without further ado, here is the visualization. (I left the old text in here.)\n",
    " \n",
    "I license this code with the CC-BY-SA 4.0 license. Please link to my blog post or the original github source (linked from the blog post) with the attribution notice.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Did you ever wish to get a concise picture of your PyTorch model's structure and found that too hard to get?\n",
    "\n",
    "\n",
    "Recently, I did some work that involved looking at model structure in some detail. For my write-up, I wanted to get a diagram of some model structures. Even though it is a relatively common model, searching for a diagram didn't turn up something in the shape what I was looking for.\n",
    "\n",
    "So how do can we get model structure for PyTorch models? The first stop probably is the neat string representation that PyTorch provides for `nn.Modules` - even without doing anything, it'll also cover our custom models pretty well. It is, however not without shortcomings.\n",
    "\n",
    "Let's look at TorchVision's ResNet18 basic block as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicBlock(\n",
       "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "m = torchvision.models.resnet18()\n",
    "m.layer1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have two convs and two batch norms. But how are things connected? Is there one ReLU?\n",
    "\n",
    "Looking at the forward method (you can get this using Python's `inspect` module or `??` in IPython), we see some important details not in the summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def forward(self, x: Tensor) -> Tensor:\n",
      "        identity = x\n",
      "\n",
      "        out = self.conv1(x)\n",
      "        out = self.bn1(out)\n",
      "        out = self.relu(out)\n",
      "\n",
      "        out = self.conv2(out)\n",
      "        out = self.bn2(out)\n",
      "\n",
      "        if self.downsample is not None:\n",
      "            identity = self.downsample(x)\n",
      "\n",
      "        out += identity\n",
      "        out = self.relu(out)\n",
      "\n",
      "        return out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(m.layer1[0].forward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we missed the entire residual bit. Also, there are two ReLUs. Arguably, it is wrong to re-use stateless modules like this. It'll haunt you when you do things like quantization (because it becomes stateful then due to the quantization parameters) and it's mixing things too much. If you want stateless, use the functional interface.\n",
    "\n",
    "But so we can build a visualization based on JITed modules.\n",
    "\n",
    "We recurse into calls to make subgraphs and we have to take some care that the edges connecting the subgraph to the outer graph need to be part of the outer graph, but other than that, it is very straightforward, even though the details are messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def make_graph(mod, classes_to_visit=None, classes_found=None, dot=None, prefix=\"\",\n",
    "               input_preds=None, \n",
    "               parent_dot=None):\n",
    "    preds = {}\n",
    "    \n",
    "    def find_name(i, self_input, suffix=None):\n",
    "        if i == self_input:\n",
    "            return suffix\n",
    "        cur = i.node().s(\"name\")\n",
    "        if suffix is not None:\n",
    "            cur = cur + '.' + suffix\n",
    "        of = next(i.node().inputs())\n",
    "        return find_name(of, self_input, suffix=cur)\n",
    "\n",
    "    gr = mod.graph\n",
    "    toshow = []\n",
    "    # list(traced_model.graph.nodes())[0]\n",
    "    self_input = next(gr.inputs())\n",
    "    self_type = self_input.type().str().split('.')[-1]\n",
    "    preds[self_input] = (set(), set()) # inps, ops\n",
    "    \n",
    "    if dot is None:\n",
    "        dot = graphviz.Digraph(format='svg', graph_attr={'label': self_type, 'labelloc': 't'})\n",
    "        #dot.attr('node', shape='box')\n",
    "\n",
    "    seen_inpnames = set()\n",
    "    seen_edges = set()\n",
    "    \n",
    "    def add_edge(dot, n1, n2):\n",
    "        if (n1, n2) not in seen_edges:\n",
    "            seen_edges.add((n1, n2))\n",
    "            dot.edge(n1, n2)\n",
    "\n",
    "    def make_edges(pr, inpname, name, op, edge_dot=dot):\n",
    "        if op:\n",
    "            if inpname not in seen_inpnames:\n",
    "                seen_inpnames.add(inpname)\n",
    "                label_lines = [[]]\n",
    "                line_len = 0\n",
    "                for w in op:\n",
    "                    if line_len >= 20:\n",
    "                        label_lines.append([])\n",
    "                        line_len = 0\n",
    "                    label_lines[-1].append(w)\n",
    "                    line_len += len(w) + 1\n",
    "                edge_dot.node(inpname, label='\\n'.join([' '.join(w) for w in label_lines]), shape='box', style='rounded')\n",
    "                for p in pr:\n",
    "                    add_edge(edge_dot, p, inpname)\n",
    "            add_edge(edge_dot, inpname, name)\n",
    "        else:\n",
    "            for p in pr:\n",
    "                add_edge(edge_dot, p, name)\n",
    "\n",
    "    for nr, i in enumerate(list(gr.inputs())[1:]):\n",
    "        name = prefix+'inp_'+i.debugName()\n",
    "        preds[i] = {name}, set()\n",
    "        dot.node(name, shape='ellipse')\n",
    "        if input_preds is not None:\n",
    "            pr, op = input_preds[nr]\n",
    "            make_edges(pr, 'inp_'+name, name, op, edge_dot=parent_dot)\n",
    "        \n",
    "    def is_relevant_type(t):\n",
    "        kind = t.kind()\n",
    "        if kind == 'TensorType':\n",
    "            return True\n",
    "        if kind in ('ListType', 'OptionalType'):\n",
    "            return is_relevant_type(t.getElementType())\n",
    "        if kind == 'TupleType':\n",
    "            return any([is_relevant_type(tt) for tt in t.elements()])\n",
    "        return False\n",
    "\n",
    "    for n in gr.nodes():\n",
    "        only_first_ops = {'aten::expand_as'}\n",
    "        rel_inp_end = 1 if n.kind() in only_first_ops else None\n",
    "            \n",
    "        relevant_inputs = [i for i in list(n.inputs())[:rel_inp_end] if is_relevant_type(i.type())]\n",
    "        relevant_outputs = [o for o in n.outputs() if is_relevant_type(o.type())]\n",
    "        if n.kind() == 'prim::CallMethod':\n",
    "            fq_submodule_name = '.'.join([nc for nc in list(n.inputs())[0].type().str().split('.') if not nc.startswith('__')])\n",
    "            submodule_type = list(n.inputs())[0].type().str().split('.')[-1]\n",
    "            submodule_name = find_name(list(n.inputs())[0], self_input)\n",
    "            name = prefix+'.'+n.output().debugName()\n",
    "            label = prefix+submodule_name+' (' + submodule_type + ')'\n",
    "            if classes_found is not None:\n",
    "                classes_found.add(fq_submodule_name)\n",
    "            if ((classes_to_visit is None and\n",
    "                 (not fq_submodule_name.startswith('torch.nn') or \n",
    "                  fq_submodule_name.startswith('torch.nn.modules.container')))\n",
    "                or (classes_to_visit is not None and \n",
    "                    (submodule_type in classes_to_visit\n",
    "                    or fq_submodule_name in classes_to_visit))):\n",
    "                # go into subgraph\n",
    "                sub_prefix = prefix+submodule_name+'.'\n",
    "                with dot.subgraph(name=\"cluster_\"+name) as sub_dot:\n",
    "                    sub_dot.attr(label=label)\n",
    "                    submod = mod\n",
    "                    for k in  submodule_name.split('.'):\n",
    "                        submod = getattr(submod, k)\n",
    "                    make_graph(submod, dot=sub_dot, prefix=sub_prefix,\n",
    "                              input_preds = [preds[i] for i in list(n.inputs())[1:]],\n",
    "                              parent_dot=dot, classes_to_visit=classes_to_visit,\n",
    "                              classes_found=classes_found)\n",
    "                for i, o in enumerate(n.outputs()):\n",
    "                    preds[o] = {sub_prefix+f'out_{i}'}, set()\n",
    "            else:\n",
    "                dot.node(name, label=label, shape='box')\n",
    "                for i in relevant_inputs:\n",
    "                    pr, op = preds[i]\n",
    "                    make_edges(pr, prefix+i.debugName(), name, op)\n",
    "                for o in n.outputs():\n",
    "                    preds[o] = {name}, set()\n",
    "        elif n.kind() == 'prim::CallFunction':\n",
    "            funcname = list(n.inputs())[0].type().__repr__().split('.')[-1]\n",
    "            name = prefix+'.'+n.output().debugName()\n",
    "            label = funcname\n",
    "            dot.node(name, label=label, shape='box')\n",
    "            for i in relevant_inputs:\n",
    "                pr, op = preds[i]\n",
    "                make_edges(pr, prefix+i.debugName(), name, op)\n",
    "            for o in n.outputs():\n",
    "                preds[o] = {name}, set()\n",
    "        else:\n",
    "            unseen_ops = {'prim::ListConstruct', 'prim::TupleConstruct', 'aten::index', \n",
    "                          'aten::size', 'aten::slice', 'aten::unsqueeze', 'aten::squeeze',\n",
    "                          'aten::to', 'aten::view', 'aten::permute', 'aten::transpose', 'aten::contiguous',\n",
    "                          'aten::permute', 'aten::Int', 'prim::TupleUnpack', 'prim::ListUnpack', 'aten::unbind',\n",
    "                          'aten::select', 'aten::detach', 'aten::stack', 'aten::reshape', 'aten::split_with_sizes',\n",
    "                          'aten::cat', 'aten::expand', 'aten::expand_as', 'aten::_shape_as_tensor',\n",
    "                          }\n",
    "        \n",
    "            absorbing_ops = ('aten::size', 'aten::_shape_as_tensor') # probably also partially absorbing ops. :/\n",
    "            if False:\n",
    "                print(n.kind())\n",
    "                #DEBUG['kinds'].add(n.kind())\n",
    "                #DEBUG[n.kind()] = n\n",
    "                label = n.kind().split('::')[-1].rstrip('_')\n",
    "                name = prefix+'.'+relevant_outputs[0].debugName()\n",
    "                dot.node(name, label=label, shape='box', style='rounded')\n",
    "                for i in relevant_inputs:\n",
    "                    pr, op = preds[i]\n",
    "                    make_edges(pr, prefix+i.debugName(), name, op)\n",
    "                for o in n.outputs():\n",
    "                    preds[o] = {name}, set()\n",
    "            if True:\n",
    "                label = n.kind().split('::')[-1].rstrip('_')\n",
    "                pr, op = set(), set()\n",
    "                for i in relevant_inputs:\n",
    "                    apr, aop = preds[i]\n",
    "                    pr |= apr\n",
    "                    op |= aop\n",
    "                if pr and n.kind() not in unseen_ops:\n",
    "                    print(n.kind(), n)\n",
    "                if n.kind() in absorbing_ops:\n",
    "                    pr, op = set(), set()\n",
    "                elif len(relevant_inputs) > 0 and len(relevant_outputs) > 0 and n.kind() not in unseen_ops:\n",
    "                    op.add(label)\n",
    "                for o in n.outputs():\n",
    "                    preds[o] = pr, op\n",
    "\n",
    "    for i, o in enumerate(gr.outputs()):\n",
    "        name = prefix+f'out_{i}'\n",
    "        dot.node(name, shape='ellipse')\n",
    "        pr, op = preds[o]\n",
    "        make_edges(pr, 'inp_'+name, name, op)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import IPython.display\n",
    "import IPython\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# global callback and register\n",
    "registered_jit_visualizations = {}\n",
    "def on_click_in_jit_visualization(objid, t):\n",
    "    # careful, if this throws an error, you won't notice\n",
    "    registered_jit_visualizations[objid](t)\n",
    "    return\n",
    "\n",
    "class JITVisualizer:\n",
    "    def __init__(self, mod, *, classes_to_visit=None, submodules_to_visit=None, expanded_names=None):\n",
    "        self.mod = mod\n",
    "        self.classes_to_visit = classes_to_visit or []  # default to no subclasses\n",
    "        self.classes_found = set()\n",
    "        self.submodules_to_visit = submodules_to_visit or set()\n",
    "        self.expanded_names = expanded_names or set()\n",
    "        self.js_display_id = None\n",
    "        self.clickseq = []\n",
    "\n",
    "    def make_node(self, dot, name, *, clickable=False, **kwargs):\n",
    "        assert name not in self.node_ids\n",
    "        nid = str(len(self.node_names))\n",
    "        self.node_names.append(name)\n",
    "        self.node_ids[name] = nid\n",
    "        if 'label' not in kwargs:\n",
    "            dot.node(self.node_ids[name], label=name, **kwargs)\n",
    "        else:\n",
    "            dot.node(self.node_ids[name], **kwargs)\n",
    "\n",
    "    def make_edge(self, dot, n1, n2):\n",
    "        dot.edge(self.node_ids[n1], self.node_ids[n2])\n",
    "\n",
    "    def make_graph(self):\n",
    "        self.node_ids = {}\n",
    "        self.node_names = [None]\n",
    "        self.cluster_ids = {}\n",
    "        self.cluster_names = [None]\n",
    "        return self._make_graph(mod=self.mod)\n",
    "\n",
    "    def cluster_id(self, name):\n",
    "        cid = 'cluster_' + str(len(self.cluster_names))\n",
    "        self.cluster_names.append(name)\n",
    "        self.cluster_ids[name] = cid\n",
    "        return cid\n",
    "\n",
    "    def is_relevant_type(self, t):\n",
    "        kind = t.kind()\n",
    "        if kind == 'TensorType':\n",
    "            return True\n",
    "        if kind in ('ListType', 'OptionalType'):\n",
    "            return self.is_relevant_type(t.getElementType())\n",
    "        if kind == 'TupleType':\n",
    "            return any([self.is_relevant_type(tt) for tt in t.elements()])\n",
    "        return False\n",
    "\n",
    "    def make_svg(self):\n",
    "        self.DEBUG_could_expand = []\n",
    "        graph = self.make_graph()\n",
    "        with tempfile.TemporaryDirectory() as d:\n",
    "            res = graph.render(os.path.join(d, 'gr'))\n",
    "            svg = open(res).read()\n",
    "        return svg\n",
    "\n",
    "    def _make_graph(self, *, mod, dot=None, prefix=\"\", input_preds=None, parent_dot=None):\n",
    "        gr = mod.graph\n",
    "        preds = {}\n",
    "\n",
    "        def find_name(i, self_input, suffix=None):\n",
    "            if i == self_input:\n",
    "                return suffix\n",
    "            cur = i.node().s(\"name\")\n",
    "            if suffix is not None:\n",
    "                cur = cur + '.' + suffix\n",
    "            of = next(i.node().inputs())\n",
    "            return find_name(of, self_input, suffix=cur)\n",
    "\n",
    "        toshow = []\n",
    "        # list(traced_model.graph.nodes())[0]\n",
    "        self_input = next(gr.inputs())\n",
    "        self_type = self_input.type().str().split('.')[-1]\n",
    "        preds[self_input] = (set(), set())  # inps, ops\n",
    "\n",
    "        if dot is None:\n",
    "            dot = graphviz.Digraph(format='svg', graph_attr={'label': self_type, 'labelloc': 't'})\n",
    "\n",
    "        seen_inpnames = set()\n",
    "        seen_edges = set()\n",
    "\n",
    "        def add_edge(dot, n1, n2):\n",
    "            if (n1, n2) not in seen_edges:\n",
    "                seen_edges.add((n1, n2))\n",
    "                self.make_edge(dot, n1, n2)\n",
    "                #dot.edge(n1, n2)\n",
    "\n",
    "        def make_edges(pr, inpname, name, op, edge_dot=dot):\n",
    "            if op:\n",
    "                if inpname not in seen_inpnames:\n",
    "                    seen_inpnames.add(inpname)\n",
    "                    label_lines = [[]]\n",
    "                    line_len = 0\n",
    "                    for w in op:\n",
    "                        if line_len >= 20:\n",
    "                            label_lines.append([])\n",
    "                            line_len = 0\n",
    "                        label_lines[-1].append(w)\n",
    "                        line_len += len(w) + 1\n",
    "                    self.make_node(edge_dot, inpname, label='\\n'.join([' '.join(w) for w in label_lines]), shape='box',\n",
    "                                  style='rounded')\n",
    "                    for p in pr:\n",
    "                        add_edge(edge_dot, p, inpname)\n",
    "                add_edge(edge_dot, inpname, name)\n",
    "            else:\n",
    "                for p in pr:\n",
    "                    add_edge(edge_dot, p, name)\n",
    "\n",
    "        for nr, i in enumerate(list(gr.inputs())[1:]):\n",
    "            name = prefix + 'inp_' + i.debugName()\n",
    "            preds[i] = {name}, set()\n",
    "            self.make_node(dot, name, shape='ellipse')\n",
    "            if input_preds is not None:\n",
    "                pr, op = input_preds[nr]\n",
    "                make_edges(pr, 'inp_' + name, name, op, edge_dot=parent_dot)\n",
    "\n",
    "        for n in gr.nodes():\n",
    "            only_first_ops = {'aten::expand_as'}\n",
    "            rel_inp_end = 1 if n.kind() in only_first_ops else None\n",
    "\n",
    "            relevant_inputs = [i for i in list(n.inputs())[:rel_inp_end] if self.is_relevant_type(i.type())]\n",
    "            relevant_outputs = [o for o in n.outputs() if self.is_relevant_type(o.type())]\n",
    "            if n.kind() == 'prim::CallMethod':\n",
    "                fq_submodule_name = '.'.join(\n",
    "                    [nc for nc in list(n.inputs())[0].type().str().split('.') if not nc.startswith('__')])\n",
    "                submodule_type = list(n.inputs())[0].type().str().split('.')[-1]\n",
    "                submodule_name = find_name(list(n.inputs())[0], self_input)\n",
    "                name = prefix + '.' + n.output().debugName()\n",
    "                label = prefix + submodule_name + ' (' + submodule_type + ')'\n",
    "                self.classes_found.add(fq_submodule_name)  # debugging\n",
    "                if ((self.classes_to_visit is None and\n",
    "                     (not fq_submodule_name.startswith('torch.nn') or\n",
    "                      fq_submodule_name.startswith('torch.nn.modules.container')))\n",
    "                    or (self.classes_to_visit is not None and\n",
    "                        (submodule_type in self.classes_to_visit\n",
    "                         or fq_submodule_name in self.classes_to_visit))\n",
    "                    or (name in self.expanded_names)):\n",
    "                    # go into subgraph\n",
    "                    sub_prefix = prefix + submodule_name + '.'\n",
    "                    # print(\"name=cluster_\" + name, f\"{sub_prefix=}\")\n",
    "                    \n",
    "                    with dot.subgraph(name=self.cluster_id(name)) as sub_dot:\n",
    "                        sub_dot.attr(label=label)\n",
    "                        submod = mod\n",
    "                        for k in submodule_name.split('.'):\n",
    "                            submod = getattr(submod, k)\n",
    "                        self._make_graph(mod=submod, dot=sub_dot, prefix=sub_prefix,\n",
    "                                   input_preds=[preds[i] for i in list(n.inputs())[1:]],\n",
    "                                   parent_dot=dot)\n",
    "                    for i, o in enumerate(n.outputs()):\n",
    "                        preds[o] = {sub_prefix + f'out_{i}'}, set()\n",
    "                else:\n",
    "                    self.DEBUG_could_expand.append(name)\n",
    "                    # print(\"could expand\", name)\n",
    "                    self.make_node(dot, name, label=label, shape='box', clickable=True)\n",
    "                    for i in relevant_inputs:\n",
    "                        pr, op = preds[i]\n",
    "                        make_edges(pr, prefix + i.debugName(), name, op)\n",
    "                    for o in n.outputs():\n",
    "                        preds[o] = {name}, set()\n",
    "            elif n.kind() == 'prim::CallFunction':\n",
    "                funcname = list(n.inputs())[0].type().__repr__().split('.')[-1]\n",
    "                name = prefix + '.' + n.output().debugName()\n",
    "                label = funcname\n",
    "                self.make_node(dot, name, label=label, shape='box')\n",
    "                for i in relevant_inputs:\n",
    "                    pr, op = preds[i]\n",
    "                    make_edges(pr, prefix + i.debugName(), name, op)\n",
    "                for o in n.outputs():\n",
    "                    preds[o] = {name}, set()\n",
    "            else:\n",
    "                unseen_ops = {'prim::ListConstruct', 'prim::TupleConstruct', 'aten::index',\n",
    "                              'aten::size', 'aten::slice', 'aten::unsqueeze', 'aten::squeeze',\n",
    "                              'aten::to', 'aten::view', 'aten::permute', 'aten::transpose', 'aten::contiguous',\n",
    "                              'aten::permute', 'aten::Int', 'prim::TupleUnpack', 'prim::ListUnpack', 'aten::unbind',\n",
    "                              'aten::select', 'aten::detach', 'aten::stack', 'aten::reshape', 'aten::split_with_sizes',\n",
    "                              #'aten::cat', \n",
    "                              'aten::expand', 'aten::expand_as', 'aten::_shape_as_tensor',\n",
    "                              }\n",
    "\n",
    "                absorbing_ops = ('aten::size', 'aten::_shape_as_tensor')  # probably also partially absorbing ops. :/\n",
    "\n",
    "                label = n.kind().split('::')[-1].rstrip('_')\n",
    "                pr, op = set(), set()\n",
    "                for i in relevant_inputs:\n",
    "                    apr, aop = preds[i]\n",
    "                    pr |= apr\n",
    "                    op |= aop\n",
    "                #if pr and n.kind() not in unseen_ops:\n",
    "                #    print(n.kind(), n)\n",
    "                if n.kind() in absorbing_ops:\n",
    "                    pr, op = set(), set()\n",
    "                elif len(relevant_inputs) > 0 and len(relevant_outputs) > 0 and n.kind() not in unseen_ops:\n",
    "                    op.add(label)\n",
    "                for o in n.outputs():\n",
    "                    preds[o] = pr, op\n",
    "\n",
    "        for i, o in enumerate(gr.outputs()):\n",
    "            name = prefix + f'out_{i}'\n",
    "            self.make_node(dot, name, shape='ellipse')\n",
    "            pr, op = preds[o]\n",
    "            make_edges(pr, 'inp_' + name, name, op)\n",
    "        return dot\n",
    "\n",
    "    def update_javascript(self):\n",
    "        registered_jit_visualizations[id(self)] = self.show_with_lastclick\n",
    "        js = '''  var my_click_event_func = function(e){\n",
    "             var kernel = IPython.notebook.kernel;\n",
    "             var label = $('title', e.currentTarget)[0].textContent;\n",
    "             //window.alert('hello!' + label);\n",
    "             if (label.startsWith('cluster_')) {\n",
    "               label = label.slice(8) + \"1\";\n",
    "             } else {\n",
    "               label = label + \"2\";\n",
    "             }\n",
    "             //window.alert('hello!' + label);\n",
    "             kernel.execute(\"on_click_in_jit_visualization(''' +str(id(self))+''', \"+ label+ \")\");\n",
    "             $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
    "             $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);\n",
    "          };\n",
    "          $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
    "          $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);          \n",
    "          '''\n",
    "\n",
    "        if self.js_display_id is None:\n",
    "            self.js_display_id = IPython.display.display(IPython.display.Javascript(js), display_id=True)\n",
    "        else:\n",
    "            self.js_display_id.update(IPython.display.Javascript(js))\n",
    "\n",
    "    def show_with_lastclick(self, i=None):\n",
    "        if i is not None:\n",
    "            typ = i % 10\n",
    "            i = i // 10\n",
    "            if typ == 1:\n",
    "                # cluster\n",
    "                self.expanded_names.remove(self.cluster_names[i])\n",
    "            else:\n",
    "                self.expanded_names.add(self.node_names[i])\n",
    "            self.last_clicked_typ = typ\n",
    "            self.last_clicked = i\n",
    "            self.clickseq.append((typ, i))\n",
    "        svg = self.make_svg()\n",
    "        self.html.value = svg\n",
    "        self.update_javascript()\n",
    "\n",
    "\n",
    "    def show_interactive_graph(self):\n",
    "        self.html = ipywidgets.HTML(\"\")\n",
    "        self.html.add_class('tv-graph')\n",
    "        IPython.display.display(self.html)\n",
    "        self.show_with_lastclick()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications\n",
    "\n",
    "\n",
    "Let's apply it! These are the pictures from my blog post along with the code that generated them.\n",
    "\n",
    "The following code is from the [transformers library](https://github.com/huggingface/transformers/) (Copyright 2018- The Hugging Face team. Apache Licensed.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.12.0.dev0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import transformers\n",
    "\n",
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "import numpy\n",
    "\n",
    "import torch\n",
    "\n",
    "enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenizing input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = enc.tokenize(text)\n",
    "\n",
    "# Masking one of the input tokens\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Creating a dummy input\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "dummy_input = [tokens_tensor, segments_tensors]\n",
    "\n",
    "# If you are instantiating the model with `from_pretrained` you can also easily set the TorchScript flag\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n",
    "\n",
    "model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the trace\n",
    "traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])\n",
    "traced_model.eval()\n",
    "for p in traced_model.parameters():\n",
    "    p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # resolvign functions?\n",
    "    t = fn.type()\n",
    "    def lookup(fn):\n",
    "        n = str(fn.type()).split('.')[1:]\n",
    "        res = globals()[n[0]]\n",
    "        for nc in n[1:]:\n",
    "            res = getattr(res, nc)\n",
    "        return res\n",
    "    lookup(fn).graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15271d83e1bb4850b8a69fe84eb27a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='', _dom_classes=('tv-graph',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "  var my_click_event_func = function(e){\n",
       "             var kernel = IPython.notebook.kernel;\n",
       "             var label = $('title', e.currentTarget)[0].textContent;\n",
       "             //window.alert('hello!' + label);\n",
       "             if (label.startsWith('cluster_')) {\n",
       "               label = label.slice(8) + \"1\";\n",
       "             } else {\n",
       "               label = label + \"2\";\n",
       "             }\n",
       "             //window.alert('hello!' + label);\n",
       "             kernel.execute(\"on_click_in_jit_visualization(140392687413664, \"+ label+ \")\");\n",
       "             $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
       "             $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);\n",
       "          };\n",
       "          $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
       "          $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);          \n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz = JITVisualizer(traced_model, expanded_names={'.3379'})\n",
    "viz.show_interactive_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336fefce6e3b4e418b4fd93cc35b5070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='', _dom_classes=('tv-graph',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "  var my_click_event_func = function(e){\n",
       "             var kernel = IPython.notebook.kernel;\n",
       "             var label = $('title', e.currentTarget)[0].textContent;\n",
       "             //window.alert('hello!' + label);\n",
       "             if (label.startsWith('cluster_')) {\n",
       "               label = label.slice(8) + \"1\";\n",
       "             } else {\n",
       "               label = label + \"2\";\n",
       "             }\n",
       "             //window.alert('hello!' + label);\n",
       "             kernel.execute(\"on_click_in_jit_visualization(140393757001376, \"+ label+ \")\");\n",
       "             $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
       "             $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);\n",
       "          };\n",
       "          $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
       "          $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);          \n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod = getattr(traced_model.encoder.layer, \"0\") # traced_model.encoder.layer[0]\n",
    "\n",
    "\n",
    "viz = JITVisualizer(getattr(traced_model.encoder.layer, \"0\"), expanded_names={'.9', 'attention..7'}) # classes_to_visit={'BertAttention', 'BertSelfAttention'}\n",
    "viz.show_interactive_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torchvision.models.resnet18()\n",
    "tm = torch.jit.trace(m, [torch.randn(1, 3, 224, 224)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicBlock(\n",
       "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torchvision.models.resnet18()\n",
    "m.layer1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def forward(self, x: Tensor) -> Tensor:\n",
      "        identity = x\n",
      "\n",
      "        out = self.conv1(x)\n",
      "        out = self.bn1(out)\n",
      "        out = self.relu(out)\n",
      "\n",
      "        out = self.conv2(out)\n",
      "        out = self.bn2(out)\n",
      "\n",
      "        if self.downsample is not None:\n",
      "            identity = self.downsample(x)\n",
      "\n",
      "        out += identity\n",
      "        out = self.relu(out)\n",
      "\n",
      "        return out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(m.layer1[0].forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25d3ca1928f46c9abc75a2006b77bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='', _dom_classes=('tv-graph',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "  var my_click_event_func = function(e){\n",
       "             var kernel = IPython.notebook.kernel;\n",
       "             var label = $('title', e.currentTarget)[0].textContent;\n",
       "             //window.alert('hello!' + label);\n",
       "             if (label.startsWith('cluster_')) {\n",
       "               label = label.slice(8) + \"1\";\n",
       "             } else {\n",
       "               label = label + \"2\";\n",
       "             }\n",
       "             //window.alert('hello!' + label);\n",
       "             kernel.execute(\"on_click_in_jit_visualization(140393758797776, \"+ label+ \")\");\n",
       "             $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
       "             $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);\n",
       "          };\n",
       "          $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
       "          $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);          \n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz = JITVisualizer(tm, expanded_names={'.1617', 'layer1..6', 'layer1..7'})\n",
    "viz.show_interactive_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cd94f7cc824e4dadf5988f7f754d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='', _dom_classes=('tv-graph',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "  var my_click_event_func = function(e){\n",
       "             var kernel = IPython.notebook.kernel;\n",
       "             var label = $('title', e.currentTarget)[0].textContent;\n",
       "             //window.alert('hello!' + label);\n",
       "             if (label.startsWith('cluster_')) {\n",
       "               label = label.slice(8) + \"1\";\n",
       "             } else {\n",
       "               label = label + \"2\";\n",
       "             }\n",
       "             //window.alert('hello!' + label);\n",
       "             kernel.execute(\"on_click_in_jit_visualization(140393473497264, \"+ label+ \")\");\n",
       "             $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
       "             $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);\n",
       "          };\n",
       "          $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
       "          $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);          \n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz = JITVisualizer(getattr(tm.layer1, \"0\"))\n",
    "viz.show_interactive_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf072e70faa465b8ccd916b4317cd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='', _dom_classes=('tv-graph',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "  var my_click_event_func = function(e){\n",
       "             var kernel = IPython.notebook.kernel;\n",
       "             var label = $('title', e.currentTarget)[0].textContent;\n",
       "             //window.alert('hello!' + label);\n",
       "             if (label.startsWith('cluster_')) {\n",
       "               label = label.slice(8) + \"1\";\n",
       "             } else {\n",
       "               label = label + \"2\";\n",
       "             }\n",
       "             //window.alert('hello!' + label);\n",
       "             kernel.execute(\"on_click_in_jit_visualization(140393761969776, \"+ label+ \")\");\n",
       "             $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
       "             $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);\n",
       "          };\n",
       "          $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
       "          $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);          \n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = torchvision.models.segmentation.fcn_resnet50()\n",
    "tm = torch.jit.trace(m, [torch.randn(1, 3, 224, 224)], strict=False)\n",
    "#d = make_graph(tm, classes_to_visit={'IntermediateLayerGetter', 'FCNHead'})\n",
    "viz = JITVisualizer(tm, expanded_names={'.4164', '.4165'})\n",
    "viz.show_interactive_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_249444/619878601.py:6: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert inp.shape[0] == 1\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:3878: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  (torch.floor((input.size(i + 2).float() * torch.tensor(scale_factors[i], dtype=torch.float32)).float()))\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/detection/anchor_utils.py:124: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  torch.empty((), dtype=torch.int64, device=device).fill_(image_size[0] // g[0]),\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/detection/anchor_utils.py:125: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  torch.empty((), dtype=torch.int64, device=device).fill_(image_size[1] // g[1]),\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/detection/rpn.py:61: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  A = Ax4 // 4\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/detection/rpn.py:62: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  C = AxC // A\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/ops/boxes.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes_x = torch.min(boxes_x, torch.tensor(width, dtype=boxes.dtype, device=boxes.device))\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/ops/boxes.py:158: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes_y = torch.min(boxes_y, torch.tensor(height, dtype=boxes.dtype, device=boxes.device))\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/detection/transform.py:291: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(s, dtype=torch.float32, device=boxes.device)\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/detection/transform.py:292: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  / torch.tensor(s_orig, dtype=torch.float32, device=boxes.device)\n"
     ]
    }
   ],
   "source": [
    "class Detection(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m = torchvision.models.detection.fasterrcnn_resnet50_fpn().eval()\n",
    "    def forward(self, inp):\n",
    "        assert inp.shape[0] == 1\n",
    "        res, = self.m(inp)\n",
    "        return res['boxes'], res['labels'], res['scores']\n",
    "\n",
    "tm = torch.jit.trace(Detection(), [torch.randn(1, 3, 224, 224)], check_trace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8e7055cb31478b956a0ab84c0ee8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='', _dom_classes=('tv-graph',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "  var my_click_event_func = function(e){\n",
       "             var kernel = IPython.notebook.kernel;\n",
       "             var label = $('title', e.currentTarget)[0].textContent;\n",
       "             //window.alert('hello!' + label);\n",
       "             if (label.startsWith('cluster_')) {\n",
       "               label = label.slice(8) + \"1\";\n",
       "             } else {\n",
       "               label = label + \"2\";\n",
       "             }\n",
       "             //window.alert('hello!' + label);\n",
       "             kernel.execute(\"on_click_in_jit_visualization(140393763957632, \"+ label+ \")\");\n",
       "             $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
       "             $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);\n",
       "          };\n",
       "          $(\".tv-graph .node\").on(\"click\", my_click_event_func);\n",
       "          $(\".tv-graph .cluster\").on(\"click\", my_click_event_func);          \n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz = JITVisualizer(tm)\n",
    "viz.show_interactive_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6138d8b8985c412bb6e5ddb2331fce30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='', _dom_classes=('tv-graph',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz.expanded_names = {'.8220', 'm..92', 'm..93'}\n",
    "viz.show_interactive_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
